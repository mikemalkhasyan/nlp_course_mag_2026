{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7v8zC8vD8z1t",
        "outputId": "9ecb7efa-c681-4f6b-9826-4b76f8342b44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'nlp_course_mag_2026'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 3 (delta 0), reused 3 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (3/3), done.\n",
            "/content/nlp_course_mag_2026/nlp_course_mag_2026\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/karennik98/nlp_course_mag_2026.git\n",
        "%cd nlp_course_mag_2026"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing the required packages\n"
      ],
      "metadata": {
        "id": "7nPTk48k-i5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim\n",
        "!pip install -U scikit-learn\n"
      ],
      "metadata": {
        "id": "KSDc1VWj_LM_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ba06279-d293-4558-e5a6-fc1eec3ddce1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.1.1)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.8.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy>=1.24.1 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Downloading scikit_learn-1.8.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (8.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "Successfully installed scikit-learn-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make Model Train\n"
      ],
      "metadata": {
        "id": "kriTp_Uu_b0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from collections import defaultdict\n",
        "\n",
        "from gensim import corpora\n",
        "from gensim.models import LdaModel\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "def preprocess(text):\n",
        "  return [word for word in text.lower().split() if word not in STOPWORDS]\n",
        "\n",
        "#Loading dataset\n",
        "dataset = fetch_20newsgroups(\n",
        "    subset=\"train\",\n",
        "    remove=(\"headers\", \"footers\", \"quotes\")\n",
        ")\n",
        "\n",
        "documents = dataset.data[:1000]\n",
        "\n",
        "processed_docs = [preprocess(doc) for doc in documents]\n",
        "\n",
        "dictionary = corpora.Dictionary(processed_docs)\n",
        "\n",
        "dictionary.filter_extremes(\n",
        "    no_below=5,\n",
        "    no_above=0.5,\n",
        ")\n",
        "\n",
        "corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
        "\n",
        "lda_model = LdaModel(\n",
        "    corpus=corpus,\n",
        "    id2word=dictionary,\n",
        "    num_topics=10,\n",
        "    passes=15,\n",
        "    alpha=\"auto\",\n",
        "    eta=\"auto\",\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "os.makedirs(\"models\", exist_ok=True)\n",
        "\n",
        "lda_model.save(\"models/lda_model.model\")\n",
        "dictionary.save(\"models/dictionary.dict\")\n",
        "\n",
        "#Topics\n",
        "for idx, topic in lda_model.print_topics(num_topics=10, num_words=15):\n",
        "    print(f\"Topic {idx}: {topic}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEqMGEHC_hWK",
        "outputId": "e9117ae4-4c0f-40a6-ed8b-a32d5094f45c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 0: 0.131*\"1\" + 0.069*\"0\" + 0.046*\"2\" + 0.026*\"---\" + 0.020*\"3\" + 0.018*\"4\" + 0.014*\"period\" + 0.012*\"power\" + 0.010*\"5\" + 0.008*\"*\" + 0.007*\"8\" + 0.007*\"7\" + 0.007*\"second\" + 0.007*\"-\" + 0.006*\"1,\"\n",
            "Topic 1: 0.095*\"-\" + 0.015*\"armenian\" + 0.012*\"armenians\" + 0.010*\"good\" + 0.008*\"people\" + 0.007*\"turkish\" + 0.006*\"genocide\" + 0.006*\"excellent\" + 0.006*\"russian\" + 0.005*\"missing\" + 0.004*\"x-soviet\" + 0.004*\"like\" + 0.004*\"came\" + 0.004*\"said\" + 0.004*\"new\"\n",
            "Topic 2: 0.010*\"don't\" + 0.009*\"like\" + 0.008*\"know\" + 0.007*\"right\" + 0.007*\"think\" + 0.006*\"it's\" + 0.006*\"car\" + 0.006*\"drive\" + 0.006*\"lot\" + 0.005*\"want\" + 0.005*\"run\" + 0.004*\"look\" + 0.004*\"didn't\" + 0.004*\"program\" + 0.004*\"it.\"\n",
            "Topic 3: 0.012*\"space\" + 0.009*\"nasa\" + 0.008*\"shuttle\" + 0.008*\"government\" + 0.007*\"turkish\" + 0.006*\"people\" + 0.006*\"mission\" + 0.005*\"-\" + 0.005*\"military\" + 0.004*\"muslim\" + 0.004*\"killed\" + 0.004*\"medical\" + 0.004*\"turks\" + 0.004*\"runs\" + 0.004*\"better\"\n",
            "Topic 4: 0.009*\"people\" + 0.007*\"use\" + 0.007*\"health\" + 0.006*\"--\" + 0.006*\"jesus\" + 0.005*\"know\" + 0.005*\"think\" + 0.004*\"new\" + 0.004*\"israel\" + 0.004*\"like\" + 0.004*\"public\" + 0.004*\"bible\" + 0.004*\"good\" + 0.004*\"word\" + 0.004*\"said\"\n",
            "Topic 5: 0.127*\".\" + 0.013*\"|\" + 0.008*\"x\" + 0.007*\"don't\" + 0.007*\"line\" + 0.006*\"problem\" + 0.006*\"--\" + 0.006*\"know\" + 0.005*\"program\" + 0.005*\"good\" + 0.005*\"video\" + 0.005*\"need\" + 0.005*\"-\" + 0.005*\"people\" + 0.004*\"use\"\n",
            "Topic 6: 0.014*\"jesus\" + 0.009*\"know\" + 0.007*\"like\" + 0.007*\"people\" + 0.007*\"matthew\" + 0.007*\"spirit\" + 0.006*\"but,\" + 0.006*\"-\" + 0.005*\"i'm\" + 0.005*\"holy\" + 0.005*\"]\" + 0.005*\"think\" + 0.005*\"said\" + 0.005*\"church\" + 0.005*\"god\"\n",
            "Topic 7: 0.042*\"=\" + 0.022*\"|\" + 0.012*\"*\" + 0.011*\"use\" + 0.010*\"}\" + 0.010*\"/\" + 0.009*\"help\" + 0.008*\"new\" + 0.008*\"thanks\" + 0.007*\"i've\" + 0.007*\"--\" + 0.007*\"file\" + 0.006*\"(\" + 0.006*\"double\" + 0.006*\"know\"\n",
            "Topic 8: 0.033*\":\" + 0.010*\"don't\" + 0.009*\"like\" + 0.008*\"it's\" + 0.008*\"people\" + 0.008*\"think\" + 0.008*\"i'm\" + 0.006*\"it.\" + 0.005*\"believe\" + 0.005*\"good\" + 0.005*\"time\" + 0.005*\"--\" + 0.005*\"you're\" + 0.005*\"argument\" + 0.005*\"i've\"\n",
            "Topic 9: 0.016*\"windows\" + 0.015*\"#\" + 0.010*\"use\" + 0.008*\"want\" + 0.008*\"know\" + 0.008*\"don't\" + 0.007*\"i'm\" + 0.007*\"need\" + 0.007*\"software\" + 0.006*\"--\" + 0.006*\"like\" + 0.005*\"data\" + 0.005*\"i've\" + 0.005*\"dos\" + 0.005*\"think\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Topic Labeling\n"
      ],
      "metadata": {
        "id": "A27jKjLCB4uE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from gensim.models import LdaModel\n",
        "from gensim import corpora\n",
        "\n",
        "lda_model = LdaModel.load(\"models/lda_model.model\")\n",
        "dictionary = corpora.Dictionary.load(\"models/dictionary.dict\")\n",
        "\n",
        "topic_labels = {}\n",
        "\n",
        "for topic_id in range(lda_model.num_topics):\n",
        "  print(f\"\\nTopic {topic_id}\")\n",
        "\n",
        "  words = lda_model.show_topic(topic_id, topn=20)\n",
        "\n",
        "  for word, prob in words:\n",
        "    print(f\"{word:<15} {prob:.4f}\")\n",
        "\n",
        "  label = input(\"\\nEnter a meaningful name (or press Enter to skip): \")\n",
        "\n",
        "  if label.strip() == \"\":\n",
        "    topic_labels[topic_id] = f\"Topic {topic_id}\"\n",
        "  else:\n",
        "    topic_labels[topic_id] = label.strip()\n",
        "\n",
        "with open(\"models/topic_labels.json\", \"w\") as f:\n",
        "    json.dump(topic_labels, f, indent=4)\n",
        "\n",
        "print(\"\\nFinal Topic Summary:\\n\")\n",
        "\n",
        "for topic_id, label in topic_labels.items():\n",
        "    print(f\"{topic_id}: {label}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPV6O750C0Ig",
        "outputId": "5a936b7c-f247-44a6-de62-9654fbc52994"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Topic 0\n",
            "1               0.1313\n",
            "0               0.0692\n",
            "2               0.0464\n",
            "---             0.0261\n",
            "3               0.0199\n",
            "4               0.0184\n",
            "period          0.0145\n",
            "power           0.0122\n",
            "5               0.0101\n",
            "*               0.0080\n",
            "8               0.0073\n",
            "7               0.0070\n",
            "second          0.0066\n",
            "-               0.0066\n",
            "1,              0.0065\n",
            "6               0.0058\n",
            "card            0.0056\n",
            "2,              0.0054\n",
            "3,              0.0050\n",
            "20              0.0048\n",
            "\n",
            "Enter a meaningful name (or press Enter to skip): \n",
            "\n",
            "Topic 1\n",
            "-               0.0952\n",
            "armenian        0.0146\n",
            "armenians       0.0115\n",
            "good            0.0101\n",
            "people          0.0079\n",
            "turkish         0.0066\n",
            "genocide        0.0062\n",
            "excellent       0.0062\n",
            "russian         0.0058\n",
            "missing         0.0049\n",
            "x-soviet        0.0044\n",
            "like            0.0044\n",
            "came            0.0043\n",
            "said            0.0040\n",
            "new             0.0040\n",
            "o               0.0038\n",
            "right           0.0036\n",
            "fair            0.0034\n",
            "left            0.0031\n",
            "war             0.0030\n",
            "\n",
            "Enter a meaningful name (or press Enter to skip): \n",
            "\n",
            "Topic 2\n",
            "don't           0.0096\n",
            "like            0.0090\n",
            "know            0.0082\n",
            "right           0.0065\n",
            "think           0.0065\n",
            "it's            0.0063\n",
            "car             0.0058\n",
            "drive           0.0058\n",
            "lot             0.0057\n",
            "want            0.0053\n",
            "run             0.0048\n",
            "look            0.0044\n",
            "didn't          0.0043\n",
            "program         0.0042\n",
            "it.             0.0042\n",
            "sure            0.0042\n",
            "power           0.0039\n",
            "window          0.0039\n",
            "new             0.0038\n",
            "x               0.0037\n",
            "\n",
            "Enter a meaningful name (or press Enter to skip): \n",
            "\n",
            "Topic 3\n",
            "space           0.0121\n",
            "nasa            0.0093\n",
            "shuttle         0.0082\n",
            "government      0.0078\n",
            "turkish         0.0071\n",
            "people          0.0058\n",
            "mission         0.0058\n",
            "-               0.0047\n",
            "military        0.0047\n",
            "muslim          0.0045\n",
            "killed          0.0042\n",
            "medical         0.0040\n",
            "turks           0.0040\n",
            "runs            0.0038\n",
            "better          0.0037\n",
            "want            0.0036\n",
            "u.s.            0.0034\n",
            "dr.             0.0033\n",
            "team            0.0033\n",
            "following       0.0033\n",
            "\n",
            "Enter a meaningful name (or press Enter to skip): \n",
            "\n",
            "Topic 4\n",
            "people          0.0086\n",
            "use             0.0070\n",
            "health          0.0068\n",
            "--              0.0063\n",
            "jesus           0.0061\n",
            "know            0.0053\n",
            "think           0.0049\n",
            "new             0.0044\n",
            "israel          0.0040\n",
            "like            0.0039\n",
            "public          0.0037\n",
            "bible           0.0037\n",
            "good            0.0036\n",
            "word            0.0036\n",
            "said            0.0035\n",
            "god             0.0035\n",
            "way             0.0033\n",
            "1993            0.0033\n",
            "state           0.0032\n",
            "got             0.0031\n",
            "\n",
            "Enter a meaningful name (or press Enter to skip): \n",
            "\n",
            "Topic 5\n",
            ".               0.1274\n",
            "|               0.0129\n",
            "x               0.0076\n",
            "don't           0.0069\n",
            "line            0.0068\n",
            "problem         0.0056\n",
            "--              0.0056\n",
            "know            0.0056\n",
            "program         0.0050\n",
            "good            0.0050\n",
            "video           0.0049\n",
            "need            0.0047\n",
            "-               0.0046\n",
            "people          0.0046\n",
            "use             0.0045\n",
            "display         0.0041\n",
            "it's            0.0041\n",
            "point           0.0041\n",
            "b               0.0041\n",
            "information     0.0038\n",
            "\n",
            "Enter a meaningful name (or press Enter to skip): \n",
            "\n",
            "Topic 6\n",
            "jesus           0.0139\n",
            "know            0.0088\n",
            "like            0.0072\n",
            "people          0.0070\n",
            "matthew         0.0067\n",
            "spirit          0.0066\n",
            "but,            0.0065\n",
            "-               0.0063\n",
            "i'm             0.0054\n",
            "holy            0.0053\n",
            "]               0.0053\n",
            "think           0.0051\n",
            "said            0.0050\n",
            "church          0.0049\n",
            "god             0.0047\n",
            "it's            0.0047\n",
            "don't           0.0047\n",
            "&               0.0044\n",
            "m               0.0043\n",
            "father          0.0042\n",
            "\n",
            "Enter a meaningful name (or press Enter to skip): \n",
            "\n",
            "Topic 7\n",
            "=               0.0418\n",
            "|               0.0217\n",
            "*               0.0117\n",
            "use             0.0109\n",
            "}               0.0104\n",
            "/               0.0098\n",
            "help            0.0090\n",
            "new             0.0078\n",
            "thanks          0.0076\n",
            "i've            0.0069\n",
            "--              0.0068\n",
            "file            0.0065\n",
            "(               0.0062\n",
            "double          0.0061\n",
            "know            0.0058\n",
            "information     0.0057\n",
            "i'm             0.0056\n",
            "think           0.0053\n",
            "can't           0.0052\n",
            "it.             0.0052\n",
            "\n",
            "Enter a meaningful name (or press Enter to skip): \n",
            "\n",
            "Topic 8\n",
            ":               0.0331\n",
            "don't           0.0101\n",
            "like            0.0086\n",
            "it's            0.0085\n",
            "people          0.0081\n",
            "think           0.0080\n",
            "i'm             0.0075\n",
            "it.             0.0057\n",
            "believe         0.0055\n",
            "good            0.0052\n",
            "time            0.0052\n",
            "--              0.0051\n",
            "you're          0.0051\n",
            "argument        0.0051\n",
            "i've            0.0045\n",
            "know            0.0042\n",
            "true            0.0040\n",
            "thing           0.0035\n",
            "things          0.0035\n",
            "got             0.0034\n",
            "\n",
            "Enter a meaningful name (or press Enter to skip): \n",
            "\n",
            "Topic 9\n",
            "windows         0.0157\n",
            "#               0.0152\n",
            "use             0.0103\n",
            "want            0.0083\n",
            "know            0.0081\n",
            "don't           0.0078\n",
            "i'm             0.0073\n",
            "need            0.0070\n",
            "software        0.0069\n",
            "--              0.0062\n",
            "like            0.0062\n",
            "data            0.0054\n",
            "i've            0.0053\n",
            "dos             0.0053\n",
            "think           0.0051\n",
            "i'd             0.0047\n",
            "images          0.0046\n",
            "time            0.0044\n",
            "image           0.0043\n",
            "video           0.0043\n",
            "\n",
            "Enter a meaningful name (or press Enter to skip): \n",
            "\n",
            "Final Topic Summary:\n",
            "\n",
            "0: Topic 0\n",
            "1: Topic 1\n",
            "2: Topic 2\n",
            "3: Topic 3\n",
            "4: Topic 4\n",
            "5: Topic 5\n",
            "6: Topic 6\n",
            "7: Topic 7\n",
            "8: Topic 8\n",
            "9: Topic 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference Script"
      ],
      "metadata": {
        "id": "wrUaG59SEdFP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "from gensim.models import LdaModel\n",
        "from gensim import corpora\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "\n",
        "def preprocess(text):\n",
        "  return [word for word in text.lower().split() if word not in STOPWORDS]\n",
        "\n",
        "lda_model = LdaModel.load(\"models/lda_model.model\")\n",
        "dictionary = corpora.Dictionary.load(\"models/dictionary.dict\")\n",
        "\n",
        "try:\n",
        "    with open(\"models/topic_labels.json\", \"r\") as f:\n",
        "        topic_labels = json.load(f)\n",
        "except:\n",
        "    topic_labels = {i: f\"Topic {i}\" for i in range(lda_model.num_topics)}\n",
        "\n",
        "#Load topics summary\n",
        "for topic_id in range(lda_model.num_topics):\n",
        "    label = topic_labels.get(str(topic_id), f\"Topic {topic_id}\")\n",
        "    words = lda_model.show_topic(topic_id, topn=5)\n",
        "    word_list = \", \".join([w for w, _ in words])\n",
        "\n",
        "    print(f\"{topic_id}: {label}\")\n",
        "    print(f\"   Top words: {word_list}\\n\")\n",
        "\n",
        "def classify_document(text):\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"Document Preview:\")\n",
        "    print(text[:200], \"...\\n\")\n",
        "\n",
        "    processed = preprocess(text)\n",
        "    bow = dictionary.doc2bow(processed)\n",
        "\n",
        "    topics = lda_model.get_document_topics(bow)\n",
        "    topics = sorted(topics, key=lambda x: x[1], reverse=True)[:3]\n",
        "\n",
        "    print(\"Top 3 Topics:\\n\")\n",
        "\n",
        "    for topic_id, prob in topics:\n",
        "        label = topic_labels.get(str(topic_id), f\"Topic {topic_id}\")\n",
        "        print(f\"{label} (Probability: {prob:.4f})\")\n",
        "\n",
        "        words = lda_model.show_topic(topic_id, topn=5)\n",
        "        word_list = \", \".join([w for w, _ in words])\n",
        "        print(f\"   Top words: {word_list}\\n\")\n",
        "\n",
        "samples = [\n",
        "    \"The new graphics card delivers amazing performance for gaming. The GPU can handle 4K resolution easily with ray tracing enabled. Gamers will love the improved frame rates.\",\n",
        "\n",
        "    \"Scientists discovered a new exoplanet orbiting a distant star in the habitable zone. The research team published their findings in Nature journal. This discovery could provide insights into planetary formation.\",\n",
        "\n",
        "    \"The basketball team won the championship after an incredible final game. The players celebrated with fans in the stadium. It was the team's first title in twenty years.\",\n",
        "\n",
        "    \"Congress passed a new bill regarding healthcare reform. The president is expected to sign the legislation next week. The policy will affect millions of citizens across the country.\",\n",
        "\n",
        "    \"I love cooking Italian food at home. Pasta carbonara and margherita pizza are my favorite dishes to make. Fresh ingredients make all the difference in authentic recipes.\"\n",
        "]\n",
        "\n",
        "for sample in samples:\n",
        "    classify_document(sample)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VM5Z6ofbEjW3",
        "outputId": "ae7349b4-b492-4912-92a1-008c72f25f68"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: Topic 0\n",
            "   Top words: 1, 0, 2, ---, 3\n",
            "\n",
            "1: Topic 1\n",
            "   Top words: -, armenian, armenians, good, people\n",
            "\n",
            "2: Topic 2\n",
            "   Top words: don't, like, know, right, think\n",
            "\n",
            "3: Topic 3\n",
            "   Top words: space, nasa, shuttle, government, turkish\n",
            "\n",
            "4: Topic 4\n",
            "   Top words: people, use, health, --, jesus\n",
            "\n",
            "5: Topic 5\n",
            "   Top words: ., |, x, don't, line\n",
            "\n",
            "6: Topic 6\n",
            "   Top words: jesus, know, like, people, matthew\n",
            "\n",
            "7: Topic 7\n",
            "   Top words: =, |, *, use, }\n",
            "\n",
            "8: Topic 8\n",
            "   Top words: :, don't, like, it's, people\n",
            "\n",
            "9: Topic 9\n",
            "   Top words: windows, #, use, want, know\n",
            "\n",
            "\n",
            "============================================================\n",
            "Document Preview:\n",
            "The new graphics card delivers amazing performance for gaming. The GPU can handle 4K resolution easily with ray tracing enabled. Gamers will love the improved frame rates. ...\n",
            "\n",
            "Top 3 Topics:\n",
            "\n",
            "Topic 0 (Probability: 0.6085)\n",
            "   Top words: 1, 0, 2, ---, 3\n",
            "\n",
            "Topic 4 (Probability: 0.3418)\n",
            "   Top words: people, use, health, --, jesus\n",
            "\n",
            "\n",
            "============================================================\n",
            "Document Preview:\n",
            "Scientists discovered a new exoplanet orbiting a distant star in the habitable zone. The research team published their findings in Nature journal. This discovery could provide insights into planetary  ...\n",
            "\n",
            "Top 3 Topics:\n",
            "\n",
            "Topic 3 (Probability: 0.4920)\n",
            "   Top words: space, nasa, shuttle, government, turkish\n",
            "\n",
            "Topic 1 (Probability: 0.3364)\n",
            "   Top words: -, armenian, armenians, good, people\n",
            "\n",
            "Topic 8 (Probability: 0.1248)\n",
            "   Top words: :, don't, like, it's, people\n",
            "\n",
            "\n",
            "============================================================\n",
            "Document Preview:\n",
            "The basketball team won the championship after an incredible final game. The players celebrated with fans in the stadium. It was the team's first title in twenty years. ...\n",
            "\n",
            "Top 3 Topics:\n",
            "\n",
            "Topic 0 (Probability: 0.5844)\n",
            "   Top words: 1, 0, 2, ---, 3\n",
            "\n",
            "Topic 1 (Probability: 0.3651)\n",
            "   Top words: -, armenian, armenians, good, people\n",
            "\n",
            "\n",
            "============================================================\n",
            "Document Preview:\n",
            "Congress passed a new bill regarding healthcare reform. The president is expected to sign the legislation next week. The policy will affect millions of citizens across the country. ...\n",
            "\n",
            "Top 3 Topics:\n",
            "\n",
            "Topic 8 (Probability: 0.5067)\n",
            "   Top words: :, don't, like, it's, people\n",
            "\n",
            "Topic 3 (Probability: 0.2418)\n",
            "   Top words: space, nasa, shuttle, government, turkish\n",
            "\n",
            "Topic 1 (Probability: 0.2181)\n",
            "   Top words: -, armenian, armenians, good, people\n",
            "\n",
            "\n",
            "============================================================\n",
            "Document Preview:\n",
            "I love cooking Italian food at home. Pasta carbonara and margherita pizza are my favorite dishes to make. Fresh ingredients make all the difference in authentic recipes. ...\n",
            "\n",
            "Top 3 Topics:\n",
            "\n",
            "Topic 4 (Probability: 0.4618)\n",
            "   Top words: people, use, health, --, jesus\n",
            "\n",
            "Topic 6 (Probability: 0.4462)\n",
            "   Top words: jesus, know, like, people, matthew\n",
            "\n",
            "Topic 8 (Probability: 0.0172)\n",
            "   Top words: :, don't, like, it's, people\n",
            "\n"
          ]
        }
      ]
    }
  ]
}